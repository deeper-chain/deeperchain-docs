{
    "componentChunkName": "component---src-templates-kb-template-tsx",
    "path": "/v3/advanced/hash-collections/",
    "result": {"data":{"mdx":{"frontmatter":{"slug":"/v3/advanced/hash-collections","title":"Hash Collections","hideNav":null,"section":"docs","category":"advanced"},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Hash Collections\",\n  \"slug\": \"/v3/advanced/hash-collections\",\n  \"version\": 3,\n  \"section\": \"docs\",\n  \"category\": \"advanced\",\n  \"keywords\": null\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Collections such as maps and sets are fundamental data structures. \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"sp_std\"), \" exposes them via\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/rustdocs/latest/sp_std/collections/btree_map/struct.BTreeMap.html\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"BTreeMap\")), \"\\nand\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/rustdocs/latest/sp_std/collections/btree_set/struct.BTreeSet.html\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"BTreeSet\")), \"\\nrespectively. These map closely to the implementations in Rust's standard library. However, the\\nstandard library also contains\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://doc.rust-lang.org/std/collections/struct.HashMap.html\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"HashMap\")), \" and\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://doc.rust-lang.org/std/collections/struct.HashSet.html\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"a\"\n  }, \"HashSet\")), \". Let's look into why\\nthose types are not also exposed in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"sp_std\"), \".\"), mdx(\"h2\", {\n    \"id\": \"trees-vs-hashes\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#trees-vs-hashes\",\n    \"aria-label\": \"trees vs hashes permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"className\": \"fill-current text-substrateDark dark:text-white\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Trees vs. Hashes\"), mdx(\"p\", null, \"Trees and hashes are two distinct approaches to implementing the interface of a map or set.\\nFundamentally, trees operate by comparing items: a node in the tree contains an item, and might\\ncontain references to a set of items less than the node item, and a set of items greater than the\\nnode item. Tree-based maps and sets have \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"O(log n)\"), \" performance characteristics for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"insert\"), \",\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"remove\"), \", and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"contains\"), \", where \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"n\"), \" is the number of items currently contained in the collection.\"), mdx(\"p\", null, \"Hashes, on the other hand, lay out a number of \\\"buckets\\\" in memory. Each bucket contains a list of\\nitems. Their method of operation is to hash each item: reduce it via some hash function into a\\nnumber. Then, they use the hash value to select which bucket should contain the item. Finally, in\\nthe event that the bucket is not empty, items are handled in unordered manner; the list is scanned\\nlinearly. Hash-based maps and sets have \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"O(1)\"), \" performance characteristics for \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"insert\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"remove\"), \",\\nand \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"contains\"), \": their performance does not depend on the number of items they contain.\"), mdx(\"p\", null, \"Clearly, hash-based implementations are faster than tree-based implementations for large \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"n\"), \".\\nHowever, most modern hash implementations require non-determinism in order to operate properly.\"), mdx(\"h2\", {\n    \"id\": \"non-determinism-in-hash-collections\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#non-determinism-in-hash-collections\",\n    \"aria-label\": \"non determinism in hash collections permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"className\": \"fill-current text-substrateDark dark:text-white\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Non-determinism in hash collections\"), mdx(\"p\", null, \"The transform from an arbitrary hashable piece of data into a hash bucket for a particular hash\\ntable typically occurs in two phases: first, the data is hashed into a single number, the hash\\nvalue. Then, the hash value is transformed into the index of a particular bucket. While in principle\\nan attack could target either phase of that process, in practice, existing attacks focus on the\\nhasher, because that requires less knowledge about the program's internal state.\"), mdx(\"p\", null, \"In 2003, researchers discovered \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://static.usenix.org/event/sec03/tech/full_papers/crosby/crosby_html/\"\n  }, \"an\\nattack\"), \" on hash\\ncollections which operate in this way. In 2011, other researchers\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/watch?v=R2Cq3CLI6H8\"\n  }, \"demonstrated\"), \" a way to use this attack on software\\nwritten in several languages popular at the time.\"), mdx(\"p\", null, \"The attack is simple: generate a large number of inputs, all of which hash into the same bucket.\\nThis means that instead of taking constant time for an insert, you need to spend time proportional\\nto the number of items already in the bucket. This in turn transforms the total cost required to\\ninsert a list of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"n\"), \" items from \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"O(n)\"), \" to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"O(n**2)\"), \".\"), mdx(\"p\", null, \"The mitigation was also simple: generate a random value at program initialization, then include that\\nvalue in the hash function's input. This makes it impossible to pre-compute a set of inputs which\\nwill generate a collision. In 2012, it was\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://fahrplan.events.ccc.de/congress/2012/Fahrplan/events/5152.en.html\"\n  }, \"shown\"), \" that a\\ncryptographic hash function is necessary to effectively defend against hash-flooding attacks. The\\nsame presentation introduced \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/veorq/SipHash\"\n  }, \"SipHash\"), \" for that purpose. That hash\\nfunction and strategy remains the state of the art as of 2021, and forms the basis for hashes in\\nmany languages, including Rust.\"), mdx(\"p\", null, \"However, the foundation of the strategy remains a single, random number. This is incompatible with\\nblockchain applications.\"), mdx(\"h2\", {\n    \"id\": \"non-determinism-on-the-blockchain\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#non-determinism-on-the-blockchain\",\n    \"aria-label\": \"non determinism on the blockchain permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"className\": \"fill-current text-substrateDark dark:text-white\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Non-determinism on the blockchain\"), mdx(\"p\", null, \"Blockchains are fundamentally consensus engines. At heart, this means that all the validators have\\nto do the same thing.\"), mdx(\"p\", null, \"It's trivial to imagine a runtime which intentionally behaves non-deterministically based on things\\nlike the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=55aaf4b234e2b9f70f10a11bb775bad4\"\n  }, \"location of hashmap values in\\nmemory\"), \".\\nThat's straightforward operator error; it will only happen to users who are doing things they\\nshouldn't.\"), mdx(\"p\", null, \"However, non-determinism can occur for other reasons. Consider a hashmap implementation which uses\\nthe max quantity of items in a bucket as a heuristic for when to resize itself. Now consider how\\nthat system behaves as it runs out of memory. Some nodes will believe that the block is invalid:\\nthey happened to generate internal hash seeds which prompted them to grow past the memory limits.\\nOther nodes will believe that the block is valid: their seeds prompted less growth, resulting in\\nsuccessful block execution. This forks the blockchain.\"), mdx(\"p\", null, \"This particular scenario is straightforward to guard against; just make resizing behavior a simple\\nfunction of total items contained, without any bucket size heuristics. However, it illustrates the\\nbroader case: it is very difficult to encapsulate non-determinism in a way which is\\ndeterministic across nodes. Parity has chosen not to spend the R&D effort which would be required to\\nsolve that problem.\"));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#trees-vs-hashes","title":"Trees vs. Hashes"},{"url":"#non-determinism-in-hash-collections","title":"Non-determinism in hash collections"},{"url":"#non-determinism-on-the-blockchain","title":"Non-determinism on the blockchain"}]},"fileAbsolutePath":"/root/deeperchain-docs/v3/docs/07-advanced/i-hash-collections/index.mdx"}},"pageContext":{"slug":"/v3/advanced/hash-collections","version":"3.0","locale":"en","hrefLang":"en-US","originalPath":"/v3/advanced/hash-collections/","dateFormat":"MM/DD/YYYY"}},
    "staticQueryHashes": ["1239077767","1821483254","2966362950","3280999885"]}